Training Loss,Validation Loss
0.46315997838974,0.5476
0.6229599714279175,0.6457
0.6859399676322937,0.7112
0.7216799855232239,0.6492
0.7428799867630005,0.7242
0.757420003414154,0.7238
0.7685999870300293,0.7013
0.7738800048828125,0.766
0.7816399931907654,0.7331
0.7861599922180176,0.7593
0.7906000018119812,0.7715
0.792140007019043,0.7604
0.7958799600601196,0.7668
0.7960799932479858,0.753
0.8007199764251709,0.7735
0.8014000058174133,0.7694
0.8441199660301208,0.8454
0.8550399541854858,0.8478
0.8614400029182434,0.8516
0.8631399869918823,0.8514
0.8655999898910522,0.8554
0.8663199543952942,0.8556
0.8676599860191345,0.8552
0.8685199618339539,0.8578
0.8696799874305725,0.8521
0.8700599670410156,0.8546
0.8726999759674072,0.8542
0.8727799654006958,0.8463
0.8752999901771545,0.8522
0.8737799525260925,0.8562
0.8764399886131287,0.8593
0.8758399486541748,0.8564
0.8741999864578247,0.8505
0.885979950428009,0.8698
0.8912999629974365,0.8704
0.8918799757957458,0.8703
0.8921799659729004,0.8708
0.8910999894142151,0.8721
0.8927399516105652,0.873
0.8946599960327148,0.8718
0.8945800065994263,0.8731
0.8941199779510498,0.8728
0.8939599990844727,0.8705
0.8941199779510498,0.8722
0.8943399786949158,0.8709
0.8962199687957764,0.8726
0.8958999514579773,0.8722
0.8947199583053589,0.8713
0.8955999612808228,0.8714
0.8944199681282043,0.8716
